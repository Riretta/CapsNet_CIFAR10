{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "from skimage import io\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "verbose = False\n",
    "USE_CUDA = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=128,  out_channels=256, kernel_size=9):\n",
    "           \n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=1\n",
    "                             )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if verbose: print( \"Conv input size{}\".format(x.size()))\n",
    "        output = F.relu(self.conv(x))\n",
    "        if verbose: print(\"Conv output feature matrix {}\".format(output.shape))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9):\n",
    "\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0) \n",
    "                          for _ in range(num_capsules)])\n",
    "    \n",
    "    def forward(self, x, dimension = 32*6*6):\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        u = torch.stack(u, dim=1)\n",
    "        if verbose: print( \"PrimaryCaps {}\".format(u.size()))\n",
    "        u = u.view(x.size(0), dimension, -1)\n",
    "        if verbose: print(\"PrimaryCaps size U {}\".format(u.size()))\n",
    "        output = self.squash(u)\n",
    "        if verbose: print(\"Primary Caps output {}\".format(output.size()))\n",
    "        return output\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        if verbose: print(output_tensor.size())\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=NUM_CLASSES, num_routes=32 * 6 * 6 , in_channels=8,  out_channels=16):\n",
    "        \n",
    "        super(DigitCaps, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "        if verbose: print( \"DigitCaps x {}, W {}\".format(x.size(),self.W.size()))\n",
    "        W = torch.cat([self.W] * batch_size, dim=0)\n",
    "        if verbose: print(\"DigitCaps W {}\".format(W.size()))\n",
    "        u_hat = torch.matmul(W, x)\n",
    "        if verbose: print(\"DigitCaps u_hat {}\".format(u_hat.size()))\n",
    "        \n",
    "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
    "        if USE_CUDA:\n",
    "            b_ij = b_ij.to(device)#cuda()\n",
    "\n",
    "        num_iterations = 3\n",
    "        for iteration in range(num_iterations):\n",
    "            c_ij = F.softmax(b_ij)\n",
    "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "\n",
    "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "            v_j = self.squash(s_j)\n",
    "            \n",
    "            if iteration < num_iterations - 1:\n",
    "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
    "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
    "\n",
    "        return v_j.squeeze(1)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def caps_loss(data, x, target, reconstructions):\n",
    "    return margin_loss(x, target) + reconstruction_loss(data, reconstructions)\n",
    "\n",
    "def margin_loss( x, labels, size_average=True):\n",
    "    batch_size = x.size(0)\n",
    "\n",
    "    v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
    "\n",
    "    left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
    "    right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
    "\n",
    "    if verbose : print(\"Dimensions of labels {}, left {} right {}\".format(labels.shape,left.shape,right.shape))\n",
    "    loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "    loss = loss.sum(dim=1).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def reconstruction_loss( data, reconstructions):\n",
    "    mseloss = nn.MSELoss()\n",
    "    loss = mseloss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
    "    if verbose : print(\"loss {}\".format(loss)) \n",
    "    return loss * 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Initializing Datasets and Dataloaders...\n",
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "image_datasets = {'train': datasets.CIFAR10('../data', train=True, download=True, transform=dataset_transform),'val': datasets.CIFAR10('../data', train=False, download=True, transform=dataset_transform)}\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True) , 'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True) }\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss( x, labels, size_average=True):\n",
    "    batch_size = x.size(0)\n",
    "\n",
    "    v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
    "\n",
    "    left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
    "    right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
    "\n",
    "    loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "    loss = loss.sum(dim=1).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def model_loss( x, target):\n",
    "    return margin_loss(x, target)\n",
    "\n",
    "def decoder(x, data):\n",
    "        classes = torch.sqrt((x ** 2).sum(2))\n",
    "        classes = F.softmax(classes)\n",
    "        \n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        masked = Variable(torch.eye(NUM_CLASSES))\n",
    "        if USE_CUDA:\n",
    "            masked = masked.to(device)#cuda()\n",
    "        masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
    "        \n",
    "        return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "train accuracy: 0.0\n",
      "masked [0 0 1 7 6 6 7 8 3 0]\n",
      "labels [2 4 0 5 7 4 9 5 5 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.1\n",
      "masked [0 2 0 8 6 6 1 2 4 0]\n",
      "labels [4 6 7 7 1 3 1 3 3 4]\n",
      "train accuracy: 0.1\n",
      "masked [2 9 2 7 6 4 0 0 3 0]\n",
      "labels [1 1 0 1 3 4 8 8 4 8]\n",
      "train accuracy: 0.1\n",
      "masked [6 1 2 0 0 2 3 2 9 0]\n",
      "labels [6 6 6 3 8 6 9 3 4 5]\n",
      "train accuracy: 0.3\n",
      "masked [9 0 7 9 2 0 2 0 9 2]\n",
      "labels [8 0 7 5 8 8 4 0 8 3]\n",
      "train accuracy: 0.3\n",
      "masked [2 0 7 2 9 2 0 5 6 0]\n",
      "labels [2 1 7 3 1 2 7 3 3 8]\n",
      "train accuracy: 0.3\n",
      "masked [1 6 2 6 7 8 3 6 0 7]\n",
      "labels [1 3 6 3 4 1 3 1 0 2]\n",
      "train accuracy: 0.3\n",
      "masked [2 5 4 6 7 3 0 1 0 1]\n",
      "labels [5 5 5 0 3 5 9 8 0 1]\n",
      "train accuracy: 0.5\n",
      "masked [6 0 5 7 1 2 7 6 6 1]\n",
      "labels [7 0 5 7 8 4 9 6 6 6]\n",
      "train accuracy: 0.4\n",
      "masked [5 8 1 6 4 1 7 7 0 0]\n",
      "labels [4 0 6 4 4 5 7 8 0 0]\n",
      "train accuracy: 0.5\n",
      "masked [6 0 0 7 0 8 5 2 1 7]\n",
      "labels [6 4 4 7 9 8 5 4 1 6]\n",
      "train accuracy: 0.4\n",
      "masked [6 6 2 1 0 5 0 7 9 2]\n",
      "labels [6 3 7 1 2 3 1 7 9 3]\n",
      "train accuracy: 0.6\n",
      "masked [8 0 6 1 7 8 9 6 2 2]\n",
      "labels [1 3 6 1 3 8 9 6 2 7]\n",
      "train accuracy: 0.3\n",
      "masked [7 0 9 8 6 7 6 8 4 1]\n",
      "labels [7 3 9 3 4 7 3 2 3 0]\n",
      "train accuracy: 0.7\n",
      "masked [5 1 0 2 7 4 6 1 8 9]\n",
      "labels [9 1 0 2 7 4 5 1 1 9]\n",
      "train accuracy: 0.7\n",
      "masked [2 8 7 8 6 7 5 6 8 7]\n",
      "labels [2 8 4 8 0 7 5 4 8 7]\n",
      "train accuracy: 0.6\n",
      "masked [1 8 6 6 5 5 2 7 9 8]\n",
      "labels [1 8 6 8 3 3 2 7 9 0]\n",
      "train accuracy: 0.4\n",
      "masked [7 6 5 1 8 1 6 7 7 0]\n",
      "labels [9 4 7 1 1 1 3 7 4 0]\n",
      "train accuracy: 0.7\n",
      "masked [1 5 9 8 5 0 6 2 9 8]\n",
      "labels [1 5 4 8 5 8 2 2 9 8]\n",
      "train accuracy: 0.6\n",
      "masked [5 6 2 5 1 6 0 8 0 4]\n",
      "labels [2 6 2 5 9 6 4 8 0 3]\n",
      "train accuracy: 0.9\n",
      "masked [0 8 9 8 9 8 4 8 8 9]\n",
      "labels [0 8 8 8 9 8 4 8 8 9]\n",
      "train accuracy: 0.4\n",
      "masked [5 1 6 6 2 0 5 6 9 1]\n",
      "labels [3 1 2 6 6 6 5 2 1 1]\n",
      "train accuracy: 0.3\n",
      "masked [6 1 6 9 6 7 0 7 5 4]\n",
      "labels [4 1 6 1 2 5 0 4 3 5]\n",
      "train accuracy: 0.5\n",
      "masked [5 0 7 5 0 2 8 9 8 2]\n",
      "labels [3 8 4 5 0 4 8 9 6 2]\n",
      "train accuracy: 0.5\n",
      "masked [1 1 6 4 0 5 5 5 8 1]\n",
      "labels [1 1 2 3 8 5 6 5 1 1]\n",
      "train accuracy: 0.7\n",
      "masked [6 1 0 4 1 5 0 4 1 8]\n",
      "labels [6 1 0 2 1 6 1 4 1 8]\n",
      "train accuracy: 0.6\n",
      "masked [8 8 9 6 9 2 5 1 7 6]\n",
      "labels [9 8 9 6 9 5 3 1 2 6]\n",
      "train accuracy: 0.5\n",
      "masked [5 4 8 4 5 0 1 1 2 0]\n",
      "labels [3 4 8 3 3 9 1 1 7 0]\n",
      "train accuracy: 0.6\n",
      "masked [2 9 5 6 6 1 1 2 4 9]\n",
      "labels [4 9 3 3 6 1 1 4 4 9]\n",
      "train accuracy: 0.6\n",
      "masked [7 5 7 8 5 0 0 7 8 7]\n",
      "labels [7 4 7 0 3 0 2 7 8 7]\n",
      "train accuracy: 0.3\n",
      "masked [1 5 7 6 6 0 8 9 4 0]\n",
      "labels [8 3 7 2 7 0 0 9 0 4]\n",
      "train accuracy: 0.7\n",
      "masked [1 7 1 0 8 9 6 0 9 5]\n",
      "labels [1 5 1 0 3 9 6 0 9 2]\n",
      "train accuracy: 0.7\n",
      "masked [5 5 6 8 4 9 0 7 0 9]\n",
      "labels [9 0 6 8 4 9 2 7 0 9]\n",
      "train accuracy: 0.6\n",
      "masked [8 6 8 7 0 7 2 6 5 5]\n",
      "labels [8 6 8 7 9 7 5 6 7 3]\n",
      "train accuracy: 0.5\n",
      "masked [5 6 8 2 7 2 9 7 0 9]\n",
      "labels [7 6 4 0 7 3 9 7 4 9]\n",
      "train accuracy: 0.6\n",
      "masked [0 6 6 7 9 7 2 0 5 7]\n",
      "labels [0 4 6 7 9 7 2 5 7 4]\n",
      "train accuracy: 0.8\n",
      "masked [2 8 0 7 1 9 5 1 9 6]\n",
      "labels [4 3 0 7 1 9 5 1 9 6]\n",
      "train accuracy: 0.8\n",
      "masked [4 2 4 9 9 8 0 6 7 8]\n",
      "labels [4 2 4 1 9 8 6 6 7 8]\n",
      "train accuracy: 0.5\n",
      "masked [5 8 6 1 5 5 4 5 0 0]\n",
      "labels [5 8 3 1 5 3 2 2 3 0]\n",
      "train accuracy: 0.4\n",
      "masked [5 1 0 6 2 7 4 5 1 9]\n",
      "labels [5 2 9 5 3 5 4 4 1 9]\n",
      "train accuracy: 0.1\n",
      "masked [9 5 0 7 6 8 5 4 6 7]\n",
      "labels [7 4 2 4 3 6 3 4 4 4]\n",
      "train accuracy: 0.6\n",
      "masked [7 5 8 7 6 2 7 5 9 1]\n",
      "labels [4 3 8 7 6 7 7 3 9 1]\n",
      "train accuracy: 0.6\n",
      "masked [6 2 5 0 4 8 9 5 6 8]\n",
      "labels [6 2 3 2 4 8 9 7 2 8]\n",
      "train accuracy: 0.9\n",
      "masked [4 7 9 6 9 1 1 4 6 8]\n",
      "labels [4 7 9 6 9 1 1 8 6 8]\n",
      "train accuracy: 0.9\n",
      "masked [1 9 5 5 9 4 6 8 3 4]\n",
      "labels [1 9 5 5 9 4 6 8 3 2]\n",
      "train accuracy: 0.6\n",
      "masked [5 7 1 9 9 6 2 5 4 5]\n",
      "labels [6 7 1 9 9 6 4 3 6 5]\n",
      "train accuracy: 0.9\n",
      "masked [5 9 5 5 8 1 4 1 6 0]\n",
      "labels [5 9 5 5 8 1 3 1 6 0]\n",
      "train accuracy: 0.8\n",
      "masked [5 2 8 1 7 7 5 6 1 8]\n",
      "labels [5 7 8 1 7 7 5 6 1 1]\n",
      "train accuracy: 0.7\n",
      "masked [9 0 5 6 4 4 8 2 5 6]\n",
      "labels [9 2 7 6 4 6 8 2 5 6]\n",
      "train accuracy: 0.7\n",
      "masked [4 6 4 8 9 7 0 5 5 4]\n",
      "labels [4 6 4 8 9 5 1 5 2 4]\n",
      "Epoch 1/2\n",
      "----------\n",
      "train accuracy: 0.8\n",
      "masked [5 9 9 6 7 5 1 2 0 6]\n",
      "labels [5 9 9 6 7 7 1 2 4 6]\n",
      "train accuracy: 0.7\n",
      "masked [3 0 5 1 4 8 1 8 5 9]\n",
      "labels [3 2 5 1 3 0 1 8 5 9]\n",
      "train accuracy: 0.7\n",
      "masked [8 7 5 0 1 6 9 1 4 5]\n",
      "labels [8 4 5 0 2 6 9 3 4 5]\n",
      "train accuracy: 0.9\n",
      "masked [1 4 7 5 6 1 1 8 5 9]\n",
      "labels [1 5 7 5 6 1 1 8 5 9]\n",
      "train accuracy: 0.7\n",
      "masked [7 6 5 8 5 6 9 4 9 8]\n",
      "labels [7 3 5 8 5 6 9 5 1 8]\n",
      "train accuracy: 0.6\n",
      "masked [5 0 9 7 4 6 8 0 8 5]\n",
      "labels [5 0 8 7 7 6 1 0 8 3]\n",
      "train accuracy: 0.6\n",
      "masked [7 3 7 3 4 0 4 2 6 3]\n",
      "labels [2 2 7 3 4 0 7 2 6 6]\n",
      "train accuracy: 0.8\n",
      "masked [4 0 7 1 9 9 8 4 8 7]\n",
      "labels [7 8 7 1 9 9 8 4 8 7]\n",
      "train accuracy: 0.7\n",
      "masked [3 9 0 7 8 0 4 1 4 8]\n",
      "labels [5 9 0 3 8 0 4 1 7 8]\n",
      "train accuracy: 0.7\n",
      "masked [7 0 8 9 3 7 5 1 8 0]\n",
      "labels [7 0 0 9 3 7 2 0 8 0]\n",
      "train accuracy: 0.5\n",
      "masked [5 0 8 5 0 5 3 4 9 9]\n",
      "labels [5 2 8 2 0 2 6 2 9 9]\n",
      "train accuracy: 0.7\n",
      "masked [8 0 9 3 8 1 1 4 6 7]\n",
      "labels [7 9 9 3 0 1 1 4 6 7]\n",
      "train accuracy: 0.4\n",
      "masked [6 8 5 9 7 0 6 0 5 2]\n",
      "labels [6 2 7 3 4 7 6 0 5 4]\n",
      "train accuracy: 0.6\n",
      "masked [4 1 4 1 6 6 2 5 0 4]\n",
      "labels [5 1 5 1 6 6 2 2 0 5]\n",
      "train accuracy: 0.6\n",
      "masked [2 0 5 1 6 8 7 1 2 5]\n",
      "labels [3 0 3 1 6 9 7 1 2 3]\n",
      "train accuracy: 0.6\n",
      "masked [4 9 9 0 7 6 0 5 4 6]\n",
      "labels [4 9 9 0 7 9 0 6 7 2]\n",
      "train accuracy: 0.7\n",
      "masked [9 4 2 4 5 0 5 5 1 9]\n",
      "labels [1 9 5 4 5 0 5 5 1 9]\n",
      "train accuracy: 0.8\n",
      "masked [8 1 4 6 2 9 6 5 7 5]\n",
      "labels [6 1 4 6 7 9 6 5 7 5]\n",
      "train accuracy: 0.6\n",
      "masked [2 7 5 2 1 1 2 5 7 4]\n",
      "labels [3 5 5 2 9 2 2 5 7 4]\n",
      "train accuracy: 0.8\n",
      "masked [7 2 2 8 0 7 0 8 3 4]\n",
      "labels [7 0 4 8 0 7 0 8 3 4]\n",
      "train accuracy: 0.5\n",
      "masked [6 0 7 6 5 0 5 3 5 9]\n",
      "labels [2 6 5 6 5 0 7 6 5 9]\n",
      "train accuracy: 0.7\n",
      "masked [9 4 4 4 5 1 9 9 0 8]\n",
      "labels [9 4 4 7 3 1 9 0 0 8]\n",
      "train accuracy: 0.5\n",
      "masked [5 2 8 5 1 9 5 3 0 0]\n",
      "labels [3 3 8 5 1 3 5 5 0 4]\n",
      "train accuracy: 0.7\n",
      "masked [0 7 6 8 5 5 9 6 1 3]\n",
      "labels [5 7 6 8 5 5 9 3 2 3]\n",
      "train accuracy: 0.9\n",
      "masked [5 5 7 3 1 6 6 5 6 8]\n",
      "labels [5 5 7 3 1 6 6 5 6 2]\n",
      "train accuracy: 0.7\n",
      "masked [2 9 4 8 5 9 1 0 5 4]\n",
      "labels [2 9 4 8 0 9 1 0 3 0]\n",
      "train accuracy: 0.6\n",
      "masked [1 4 4 4 9 1 1 3 0 8]\n",
      "labels [1 7 4 4 0 1 1 7 2 8]\n",
      "train accuracy: 0.8\n",
      "masked [1 1 8 4 7 5 8 2 2 5]\n",
      "labels [1 1 8 2 7 5 8 2 2 3]\n",
      "train accuracy: 0.6\n",
      "masked [2 9 0 0 6 8 1 6 5 6]\n",
      "labels [2 9 0 0 3 8 2 5 3 6]\n",
      "train accuracy: 1.0\n",
      "masked [1 6 8 4 9 7 9 8 1 5]\n",
      "labels [1 6 8 4 9 7 9 8 1 5]\n",
      "train accuracy: 0.7\n",
      "masked [8 6 5 0 7 6 9 4 3 1]\n",
      "labels [8 6 5 0 2 6 9 4 8 8]\n",
      "train accuracy: 0.7\n",
      "masked [2 7 4 9 0 5 3 1 0 8]\n",
      "labels [2 7 4 9 9 3 3 1 0 4]\n",
      "train accuracy: 0.6\n",
      "masked [6 9 4 5 5 0 0 7 1 0]\n",
      "labels [6 9 5 7 3 0 0 7 1 2]\n",
      "train accuracy: 0.8\n",
      "masked [6 0 4 8 9 8 8 7 9 3]\n",
      "labels [2 3 4 8 9 8 8 7 9 3]\n",
      "train accuracy: 0.9\n",
      "masked [6 8 5 6 1 1 0 8 5 3]\n",
      "labels [6 8 3 6 1 1 0 8 5 3]\n",
      "train accuracy: 1.0\n",
      "masked [1 8 2 6 0 6 7 4 6 3]\n",
      "labels [1 8 2 6 0 6 7 4 6 3]\n",
      "train accuracy: 0.8\n",
      "masked [9 6 7 9 7 9 3 1 4 1]\n",
      "labels [9 6 7 9 7 9 6 1 3 1]\n",
      "train accuracy: 0.7\n",
      "masked [5 8 8 7 0 6 1 8 5 6]\n",
      "labels [3 8 8 7 0 6 2 8 7 6]\n",
      "train accuracy: 0.5\n",
      "masked [5 1 9 9 6 6 3 7 2 6]\n",
      "labels [3 1 9 0 6 4 8 7 7 6]\n",
      "train accuracy: 0.7\n",
      "masked [1 4 5 5 4 6 9 8 7 7]\n",
      "labels [1 4 5 3 4 6 0 8 7 4]\n",
      "train accuracy: 0.4\n",
      "masked [0 6 4 6 9 1 2 4 5 5]\n",
      "labels [0 3 2 6 7 1 3 4 3 3]\n",
      "train accuracy: 0.8\n",
      "masked [8 3 1 1 4 7 9 0 4 6]\n",
      "labels [8 4 1 1 5 7 9 0 4 6]\n",
      "train accuracy: 0.6\n",
      "masked [7 6 3 4 9 4 5 2 8 0]\n",
      "labels [7 6 5 4 9 2 3 2 8 2]\n",
      "train accuracy: 0.7\n",
      "masked [8 9 4 5 7 2 1 6 6 7]\n",
      "labels [8 6 4 3 7 4 1 6 6 7]\n",
      "train accuracy: 0.8\n",
      "masked [7 4 0 0 6 5 3 2 9 3]\n",
      "labels [7 4 0 2 6 5 3 3 9 3]\n",
      "train accuracy: 0.7\n",
      "masked [4 5 8 1 9 7 7 0 6 6]\n",
      "labels [2 5 8 1 1 7 5 0 6 6]\n",
      "train accuracy: 1.0\n",
      "masked [9 2 2 8 7 3 6 1 0 1]\n",
      "labels [9 2 2 8 7 3 6 1 0 1]\n",
      "train accuracy: 0.8\n",
      "masked [7 3 9 7 3 9 4 2 8 4]\n",
      "labels [7 3 9 2 3 9 4 6 8 4]\n",
      "train accuracy: 0.9\n",
      "masked [0 8 6 0 1 5 8 8 7 4]\n",
      "labels [0 8 6 0 1 2 8 8 7 4]\n",
      "train accuracy: 0.5\n",
      "masked [1 5 4 4 8 7 2 8 5 3]\n",
      "labels [1 9 2 7 8 7 2 8 3 2]\n",
      "Epoch 2/2\n",
      "----------\n",
      "train accuracy: 0.7\n",
      "masked [2 6 8 3 5 4 9 7 4 1]\n",
      "labels [2 5 8 3 3 4 1 7 4 1]\n",
      "train accuracy: 0.8\n",
      "masked [8 8 3 4 9 5 1 3 8 4]\n",
      "labels [8 8 3 4 4 5 1 3 8 5]\n",
      "train accuracy: 0.9\n",
      "masked [6 2 4 9 5 2 2 1 7 7]\n",
      "labels [6 2 4 8 5 2 2 1 7 7]\n",
      "train accuracy: 0.6\n",
      "masked [4 4 1 0 6 6 8 8 3 0]\n",
      "labels [5 4 4 0 6 6 3 8 4 0]\n",
      "train accuracy: 0.7\n",
      "masked [7 0 6 1 3 1 8 3 6 7]\n",
      "labels [7 0 3 1 5 1 8 3 3 7]\n",
      "train accuracy: 0.7\n",
      "masked [7 6 4 5 4 3 0 1 5 7]\n",
      "labels [7 6 7 5 5 3 0 1 7 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.5\n",
      "masked [6 7 3 9 5 7 3 1 4 6]\n",
      "labels [2 7 5 9 3 4 3 1 6 6]\n",
      "train accuracy: 0.7\n",
      "masked [5 8 5 3 7 0 1 1 4 2]\n",
      "labels [2 8 5 3 5 7 1 1 4 2]\n",
      "train accuracy: 0.9\n",
      "masked [9 1 9 0 8 6 3 6 1 4]\n",
      "labels [9 1 9 0 8 6 3 6 1 7]\n",
      "train accuracy: 0.8\n",
      "masked [5 7 3 0 0 9 6 1 5 6]\n",
      "labels [5 7 5 0 5 9 6 1 5 6]\n",
      "train accuracy: 0.6\n",
      "masked [9 8 1 8 0 2 6 4 1 9]\n",
      "labels [1 1 1 8 0 0 2 4 1 9]\n",
      "train accuracy: 0.8\n",
      "masked [8 5 6 0 6 5 7 7 8 2]\n",
      "labels [8 5 3 0 2 5 7 7 8 2]\n",
      "train accuracy: 0.8\n",
      "masked [9 8 0 0 4 3 0 5 2 3]\n",
      "labels [9 8 0 8 4 3 0 5 8 3]\n",
      "train accuracy: 0.6\n",
      "masked [8 9 6 6 4 1 2 3 8 0]\n",
      "labels [8 9 6 6 4 0 6 4 1 0]\n",
      "train accuracy: 0.9\n",
      "masked [9 1 0 4 7 0 8 8 0 6]\n",
      "labels [9 1 0 4 2 0 8 8 0 6]\n",
      "train accuracy: 0.8\n",
      "masked [0 4 3 7 9 6 7 1 4 5]\n",
      "labels [0 4 3 2 9 3 7 1 4 5]\n",
      "train accuracy: 0.6\n",
      "masked [4 1 0 5 1 0 2 3 0 5]\n",
      "labels [3 1 0 3 1 0 7 5 0 5]\n",
      "train accuracy: 0.9\n",
      "masked [6 8 7 9 6 4 1 2 4 0]\n",
      "labels [6 8 7 9 6 4 1 2 4 2]\n",
      "train accuracy: 0.8\n",
      "masked [3 2 0 9 0 4 5 6 0 0]\n",
      "labels [5 2 0 9 0 1 5 6 0 0]\n",
      "train accuracy: 0.9\n",
      "masked [4 3 0 9 4 6 9 7 6 7]\n",
      "labels [4 3 0 9 4 6 9 7 2 7]\n",
      "train accuracy: 0.7\n",
      "masked [3 1 8 6 7 5 0 7 8 3]\n",
      "labels [3 1 8 6 7 5 0 4 3 2]\n",
      "train accuracy: 0.8\n",
      "masked [3 3 7 2 4 2 9 0 8 2]\n",
      "labels [3 3 9 2 4 2 9 7 8 2]\n",
      "train accuracy: 0.5\n",
      "masked [8 5 4 9 7 4 6 7 8 8]\n",
      "labels [8 3 4 6 7 4 6 3 0 0]\n",
      "train accuracy: 0.7\n",
      "masked [4 2 7 0 9 8 3 4 3 1]\n",
      "labels [4 4 3 0 9 8 3 4 5 1]\n",
      "train accuracy: 0.6\n",
      "masked [8 3 2 5 9 8 5 4 6 3]\n",
      "labels [8 3 2 5 9 0 2 2 6 2]\n",
      "train accuracy: 1.0\n",
      "masked [9 5 0 9 1 3 6 2 3 5]\n",
      "labels [9 5 0 9 1 3 6 2 3 5]\n",
      "train accuracy: 0.7\n",
      "masked [7 5 3 3 4 2 1 0 8 4]\n",
      "labels [7 5 3 3 2 2 1 0 0 5]\n",
      "train accuracy: 0.7\n",
      "masked [8 2 1 0 3 3 6 8 5 8]\n",
      "labels [8 2 1 7 4 3 4 8 5 8]\n",
      "train accuracy: 0.6\n",
      "masked [9 1 1 0 6 0 4 6 7 5]\n",
      "labels [3 8 1 0 6 0 4 6 4 7]\n",
      "train accuracy: 0.8\n",
      "masked [6 9 5 5 2 5 8 1 4 0]\n",
      "labels [6 0 5 2 2 5 8 1 4 0]\n",
      "train accuracy: 0.7\n",
      "masked [4 7 6 5 6 1 4 8 2 3]\n",
      "labels [4 7 6 5 6 1 3 0 2 2]\n",
      "train accuracy: 0.9\n",
      "masked [5 8 0 5 0 5 8 6 4 9]\n",
      "labels [5 8 0 5 0 7 8 6 4 9]\n",
      "train accuracy: 0.8\n",
      "masked [8 8 2 7 3 1 1 0 7 6]\n",
      "labels [2 8 2 7 3 1 9 0 7 6]\n",
      "train accuracy: 0.7\n",
      "masked [9 3 1 8 4 5 6 0 4 2]\n",
      "labels [9 3 1 8 4 7 2 0 2 2]\n",
      "train accuracy: 0.7\n",
      "masked [9 8 1 6 5 6 3 7 3 8]\n",
      "labels [9 8 1 6 7 6 5 7 7 8]\n",
      "train accuracy: 0.6\n",
      "masked [2 8 2 0 7 1 5 0 3 9]\n",
      "labels [8 8 7 6 7 1 5 0 4 9]\n",
      "train accuracy: 1.0\n",
      "masked [9 7 1 5 7 6 1 3 6 6]\n",
      "labels [9 7 1 5 7 6 1 3 6 6]\n",
      "train accuracy: 0.8\n",
      "masked [9 3 1 8 0 2 5 3 1 5]\n",
      "labels [9 3 1 8 7 7 5 3 1 5]\n",
      "train accuracy: 0.8\n",
      "masked [8 5 5 1 7 4 9 8 8 9]\n",
      "labels [8 5 3 1 7 4 9 8 8 2]\n",
      "train accuracy: 0.9\n",
      "masked [6 1 4 7 4 1 0 7 0 5]\n",
      "labels [6 1 9 7 4 1 0 7 0 5]\n",
      "train accuracy: 0.7\n",
      "masked [1 8 6 9 1 3 6 6 8 3]\n",
      "labels [1 8 3 9 1 5 6 6 8 7]\n",
      "train accuracy: 0.7\n",
      "masked [2 9 9 7 6 0 2 3 5 8]\n",
      "labels [2 0 9 7 8 0 2 4 5 8]\n",
      "train accuracy: 0.8\n",
      "masked [6 6 7 1 1 5 6 0 7 3]\n",
      "labels [5 2 7 1 1 5 6 0 7 3]\n",
      "train accuracy: 0.9\n",
      "masked [3 3 3 0 7 4 4 3 3 4]\n",
      "labels [3 3 3 0 5 4 4 3 3 4]\n",
      "train accuracy: 0.5\n",
      "masked [6 2 2 6 3 8 0 7 1 1]\n",
      "labels [6 2 7 4 3 8 0 5 3 2]\n",
      "train accuracy: 0.8\n",
      "masked [7 4 8 6 1 9 9 7 8 2]\n",
      "labels [7 3 3 6 1 9 9 7 8 2]\n",
      "train accuracy: 1.0\n",
      "masked [5 5 9 2 1 8 8 6 1 2]\n",
      "labels [5 5 9 2 1 8 8 6 1 2]\n",
      "train accuracy: 0.8\n",
      "masked [8 5 6 9 5 0 6 8 3 7]\n",
      "labels [8 5 4 9 2 0 6 8 3 7]\n",
      "train accuracy: 0.8\n",
      "masked [6 8 5 6 9 5 5 7 3 1]\n",
      "labels [6 8 5 2 9 2 5 7 3 1]\n",
      "train accuracy: 0.7\n",
      "masked [9 8 2 4 0 0 4 3 1 7]\n",
      "labels [9 8 8 4 0 0 4 1 9 7]\n",
      "Training time execution 1997.9637787342072\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "modules = list(model.children())[:-4]\n",
    "model=nn.Sequential(*modules)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.layer3 = nn.Sequential(ConvLayer(), PrimaryCaps(), DigitCaps())\n",
    "loss_train = []        \n",
    "accuracy_train = []\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.layer3.parameters(),lr = 0.001)\n",
    "start = time.time()\n",
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "        model.train() \n",
    "        \n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "        print('Epoch {}/{}'.format(epoch,3-1))\n",
    "        print('-'*10)\n",
    "        for batch_id, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "            #inputs, labels = next(iter(dataloaders['train']))\n",
    "\n",
    "            labels =torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = model_loss(outputs, labels)\n",
    "            masked = decoder(outputs, inputs)\n",
    "        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.data[0]\n",
    "            train_accuracy += (sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "            \n",
    "            if batch_id % 100 == 0:\n",
    "                print(\"train accuracy:\", sum(np.argmax(masked.data.cpu().numpy(), 1) == \n",
    "                                       np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "                print(\"masked {}\".format(np.argmax(masked.data.cpu().numpy(), 1)))\n",
    "                print(\"labels {}\".format(np.argmax(labels.data.cpu().numpy(), 1)))\n",
    "#                batch_accuracy.append(sum(np.argmax(preds.data.cpu().numpy(), 1) == \n",
    "#                                       np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "        \n",
    "        loss_train.append(train_loss/len(dataloaders['train']))\n",
    "        accuracy_train.append(train_accuracy/len(dataloaders['train']))\n",
    "end = time.time()\n",
    "print(\"Training time execution {}\".format(end-start))\n",
    "print(\"Loss value for training phase: {}\".format(train_loss / len(dataloaders['train'])))\n",
    "print(\"Accuracy value for training phase: {}\".format(train_accuracy / len(dataloaders['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8\n",
      "masked [3 4 8 3 9 0 9 3 2 6]\n",
      "labels [3 4 8 3 9 8 9 3 3 6]\n",
      "test accuracy: 0.7\n",
      "masked [8 5 0 3 6 0 6 7 6 0]\n",
      "labels [8 5 7 5 3 0 6 7 6 0]\n",
      "test accuracy: 0.8\n",
      "masked [4 7 4 1 0 8 6 2 2 5]\n",
      "labels [2 7 4 1 0 8 6 3 2 5]\n",
      "test accuracy: 0.9\n",
      "masked [1 4 3 6 8 3 1 6 5 6]\n",
      "labels [1 4 3 6 8 4 1 6 5 6]\n",
      "test accuracy: 0.6\n",
      "masked [0 6 7 6 0 9 1 3 5 2]\n",
      "labels [0 4 7 5 0 0 4 3 5 2]\n",
      "test accuracy: 0.8\n",
      "masked [5 5 7 0 6 2 4 7 9 7]\n",
      "labels [5 5 7 1 6 4 4 7 9 7]\n",
      "test accuracy: 0.7\n",
      "masked [9 0 3 9 2 7 8 9 5 1]\n",
      "labels [9 2 8 9 2 7 8 5 5 1]\n",
      "test accuracy: 0.8\n",
      "masked [5 6 3 3 6 0 9 0 6 3]\n",
      "labels [5 6 3 3 6 0 3 0 6 5]\n",
      "test accuracy: 0.9\n",
      "masked [6 0 3 7 7 0 5 8 7 3]\n",
      "labels [6 7 3 7 7 0 5 8 7 3]\n",
      "test accuracy: 0.8\n",
      "masked [4 2 3 9 0 5 3 6 6 6]\n",
      "labels [4 2 4 9 0 5 3 2 6 6]\n",
      "Validation time execution 62.89648675918579\n",
      "Loss value for test phase: 0.3588980734348297\n",
      "Accuracy value for test phase: 0.7514999999999983\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "start = time.time()\n",
    "for batch_id, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "    labels =torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    masked = decoder(outputs, inputs)\n",
    "    \n",
    "    loss = model_loss(outputs, labels)\n",
    "    test_loss += loss.data[0]\n",
    "    test_accuracy += (sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "    \n",
    "    if batch_id % 100 == 0:\n",
    "            print(\"test accuracy:\", sum(np.argmax(masked.data.cpu().numpy(), 1) == \n",
    "                                   np.argmax(labels.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "            print(\"masked {}\".format(np.argmax(masked.data.cpu().numpy(), 1)))\n",
    "            print(\"labels {}\".format(np.argmax(labels.data.cpu().numpy(), 1)))\n",
    "        \n",
    "            \n",
    "end = time.time()   \n",
    "print(\"Validation time execution {}\".format(end-start))\n",
    "print(\"Loss value for test phase: {}\".format(test_loss / len(dataloaders['val'])))\n",
    "print(\"Accuracy value for test phase: {}\".format(test_accuracy / len(dataloaders['val'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(9, 9), stride=(1, 1))\n",
      "    )\n",
      "    (1): PrimaryCaps(\n",
      "      (capsules): ModuleList(\n",
      "        (0): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "        (1): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "        (2): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "        (3): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "        (4): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "        (5): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "        (6): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "        (7): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
      "      )\n",
      "    )\n",
      "    (2): DigitCaps()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model)\n",
    "import matplotlib.pyplot as plt\n",
    "n_epochs = 3\n",
    "epochs = np.arange(1,n_epochs+1)\n",
    "plt.plot(epochs, loss_train, color='g')\n",
    "plt.plot(epochs, loss_train, color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training phase')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
